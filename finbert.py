# -*- coding: utf-8 -*-
"""FinBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AAx3dGevX57Sbk2rh6KzR7sFFp53aRtO
"""

import pandas as pd
import tensorflow as tf
from transformers import TFAutoModelForSequenceClassification, AutoTokenizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Load dataset
file_path = "data.csv"
df = pd.read_csv(file_path)

# Encode labels
label_encoder = LabelEncoder()
df["Sentiment"] = label_encoder.fit_transform(df["Sentiment"])

# Split data into training and testing sets
train_texts, test_texts, train_labels, test_labels = train_test_split(
    df["Sentence"].tolist(), df["Sentiment"].tolist(), test_size=0.2, random_state=42
)

# Load FinBERT tokenizer
tokenizer = AutoTokenizer.from_pretrained("yiyanghkust/finbert-tone")

# Tokenize dataset
def tokenize(texts, tokenizer, max_length=128):
    return tokenizer(
        texts,
        padding=True,
        truncation=True,
        max_length=max_length,
        return_tensors="tf"
    )

train_encodings = tokenize(train_texts, tokenizer)
test_encodings = tokenize(test_texts, tokenizer)

# Convert labels to TensorFlow tensors
train_labels = tf.convert_to_tensor(train_labels)
test_labels = tf.convert_to_tensor(test_labels)

# Load pre-trained FinBERT model
model = TFAutoModelForSequenceClassification.from_pretrained("yiyanghkust/finbert-tone", num_labels=3)

# Compile model
optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]

model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

# Train model
model.fit(
    x={"input_ids": train_encodings["input_ids"], "attention_mask": train_encodings["attention_mask"]},
    y=train_labels,
    validation_data=(
        {"input_ids": test_encodings["input_ids"], "attention_mask": test_encodings["attention_mask"]},
        test_labels
    ),
    epochs=3,
    batch_size=16
)

# Save model
model.save_pretrained("./finbert_finetuned")
tokenizer.save_pretrained("./finbert_finetuned")

print("Fine-tuning complete. Model saved.")